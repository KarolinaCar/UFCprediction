{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c03de-4207-444f-9a89-888c8431ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "BASE_URL = \"http://ufcstats.com\"  \n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\" \n",
    "DEFAULT_PAUSE_TIME = 0.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55880506-51b0-4d3e-8970-8ce14076bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_event_links():\n",
    "    full_url = f\"{BASE}/statistics/events/completed?page=all\"\n",
    "    try:\n",
    "        resp = requests.get(full_url, headers=HEAD, timeout=30)\n",
    "        html_content = resp.text\n",
    "    except Exception as e:\n",
    "        print(\"Failed to fetch event links:\", e)\n",
    "        return []  \n",
    "\n",
    "    soup = BeautifulSoup(html_content, \"lxml\")\n",
    "    \n",
    "    links = [a_tag[\"href\"] for a_tag in soup.select(\"tr.b-statistics__table-row a\")]\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40668f0-5d3d-4acf-bdd8-32a1e483084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fight_links_from_event(event_page_url):\n",
    "    try:\n",
    "        response = requests.get(event_page_url, headers=HEAD, timeout=30)\n",
    "        event_html = response.text\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(event_html, \"lxml\")\n",
    "    \n",
    "    all_links = soup.select(\"a.b-link.b-link_style_black\")\n",
    "    \n",
    "    fight_links = []\n",
    "    for link in all_links:\n",
    "        href = link.get(\"href\", \"\")\n",
    "        if \"/fight-details/\" in href:\n",
    "            fight_links.append(href)\n",
    "    \n",
    "    return fight_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e058f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_fight_details(fight_url):\n",
    "    try:\n",
    "        page_html = requests.get(fight_url, headers=HEAD, timeout=30).text\n",
    "    except:\n",
    "        print(\"Could not fetch fight:\", fight_url)\n",
    "        return {}\n",
    "\n",
    "    soup = BeautifulSoup(page_html, \"lxml\")\n",
    "\n",
    "    # Example title looks like: \"Fighter A vs Fighter B\"\n",
    "    headline = soup.select_one(\"h2.b-content__title\")\n",
    "    if headline:\n",
    "        fight_title = headline.text.strip().split(\"  \")[0]  \n",
    "    else:\n",
    "        fight_title = \"Unknown vs Unknown\"\n",
    "\n",
    "    # Breaking the title down\n",
    "    try:\n",
    "        p1, p2 = [name.strip() for name in fight_title.split(\" vs \")]\n",
    "    except:\n",
    "        p1, p2 = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    # Pulling metadata like weight class, round, etc.\n",
    "    info_tags = soup.select(\"li.b-list__box-list-item\")\n",
    "    fight_meta = {}\n",
    "    for li in info_tags:\n",
    "        if \":\" in li.text:\n",
    "            key, val = li.text.split(\":\", 1)\n",
    "            fight_meta[key.strip()] = val.strip()\n",
    "\n",
    "    # Winner is denoted by a tag in a specific spot — can be empty sometimes\n",
    "    winner_tag = soup.select_one(\n",
    "        \"div.b-fight-details__person:nth-child(1) i.b-fight-details__person-status\"\n",
    "    )\n",
    "    who_won = winner_tag.text.strip() if winner_tag else None  \n",
    "\n",
    "    # Here's the final dictionary with all the stuff we care about\n",
    "    fight_data = {\n",
    "        \"fight_id\": fight_url.split(\"/\")[-1], \n",
    "        \"event\": fight_meta.get(\"Event\"),\n",
    "        \"date\": fight_meta.get(\"Date\"),\n",
    "        \"weight_class\": fight_meta.get(\"Weight class\"),\n",
    "        \"fighter_1\": p1,\n",
    "        \"fighter_2\": p2,\n",
    "        \"winner\": who_won,\n",
    "        \"method\": fight_meta.get(\"Method\"),\n",
    "        \"round\": fight_meta.get(\"Round\"),\n",
    "        \"time\": fight_meta.get(\"Time\"),\n",
    "    }\n",
    "\n",
    "    return fight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81cc0f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(max_events=None, pause=DEFAULT_PAUSE_TIME) -> pd.DataFrame:\n",
    "    event_list = event_links()\n",
    "    if max_events:\n",
    "        event_list = event_list[:max_events]\n",
    "\n",
    "    fight_data = [] \n",
    "\n",
    "    for event_url in tqdm(event_list, desc=\"Events\", unit=\"event\"):\n",
    "        fight_links_list = fight_links(event_url)\n",
    "\n",
    "        for fight_url in fight_links_list:\n",
    "            try:\n",
    "                fight_info = parse_fight(fight_url)\n",
    "                fight_data.append(fight_info)\n",
    "            except Exception as err:\n",
    "                print(f\"Error parsing {fight_url}: {err}\")\n",
    "                continue\n",
    "\n",
    "            time.sleep(pause)  \n",
    "\n",
    "        # Dump intermediate data — just in case it crashes midway\n",
    "        partial_df = pd.DataFrame(fight_data)\n",
    "        partial_df.to_csv(\"data/fights_partial.csv\", index=False)\n",
    "\n",
    "    final_df = pd.DataFrame(fight_data)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82a65a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51010a8c399f431790b66cea3606f3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Events:   0%|          | 0/731 [00:00<?, ?event/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ fights.csv saved with 0 rows\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting UFC data crawl...\\n\")\n",
    "    \n",
    "    data_frame = crawl()\n",
    "\n",
    "    output_dir = Path(\"data\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    output_path = output_dir / \"fights.csv\"\n",
    "    data_frame.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"\\n Done! Saved {len(data_frame):,} rows to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cec8de-934b-4c62-8def-7031cfa5e17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5229a48-d722-435f-a376-6499522b6056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial setup for models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a6516-05e9-4dfd-981b-7f01d8b58257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholder for engineered dataset\n",
    "\n",
    "df = pd.read_csv('..')\n",
    "\n",
    "X = df.drop('Winner_label', axis=1)  #target name\n",
    "y = df['Winner_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee6d4d-6239-4683-b7ec-52a3ef37fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasplit (Training/testing)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43bbdc7-bcab-4985-b4d2-62b898a2825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model setup\n",
    "def train_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1af7fd-0e4a-41c5-8f0a-fbc4f3b7c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will run it when its ready\n",
    "\n",
    "#logistic regression\n",
    "print(\"Logistic Regression Results\")\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "train_evaluate_model(logistic_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "#random forest\n",
    "print(\"Random Forest Results\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "train_evaluate_model(rf_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "#XGboost\n",
    "print(\"XGBoost Results\")\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "train_evaluate_model(xgb_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb585747-d574-4e7d-8a19-c4f543a3439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For front-end use (Streamlit)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
