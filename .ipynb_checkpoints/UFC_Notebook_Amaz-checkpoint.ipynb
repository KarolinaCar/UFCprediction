{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2730c5-ecf7-44a3-a90d-1bebf0d501a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fighter_links():\n",
    "    base_url = \"http://www.ufcstats.com/statistics/fighters?char={}&page=all\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    fighter_links = []\n",
    "\n",
    "    for letter in letters:\n",
    "        url = base_url.format(letter)\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table = soup.find('table', class_='b-statistics__table')\n",
    "            if table:\n",
    "                links = table.find_all('a')\n",
    "                for link in links:\n",
    "                    href = link.get('href')\n",
    "                    if href and 'fighter-details' in href:\n",
    "                        fighter_links.append(href)\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            print(f\"Ran into an error while checking letter {letter}: {e}\")\n",
    "\n",
    "    return list(set(fighter_links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5f3ed-5ba4-46c7-941b-174878aca975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fighter_data(fighter_url):\n",
    "    response = requests.get(fighter_url, timeout=10)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    name = soup.find('span', class_='b-content__title-highlight')\n",
    "    name = name.text.strip() if name else None\n",
    "\n",
    "    record = soup.find('span', class_='b-content__title-record')\n",
    "    record = record.text.strip().replace('Record: ', '') if record else None\n",
    "\n",
    "    stats = soup.find_all('li', class_='b-list__box-list-item b-list__box-list-item_type_block')\n",
    "    data = {'Name': name, 'Record': record, 'Fighter URL': fighter_url}\n",
    "\n",
    "    for stat in stats:\n",
    "        parts = stat.text.strip().split(':')\n",
    "        if len(parts) == 2:\n",
    "            key = parts[0].strip()\n",
    "            value = parts[1].strip()\n",
    "            data[key] = value\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df10f8-1b40-4a07-a392-c8953067f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Grabbing all the fighter profile links...\")\n",
    "    fighter_links = get_fighter_links()\n",
    "    print(f\"Found {len(fighter_links)} fighters.\")\n",
    "\n",
    "    fighters_data = []\n",
    "    errors = []\n",
    "\n",
    "    for link in tqdm(fighter_links):\n",
    "        try:\n",
    "            fighter = get_fighter_data(link)\n",
    "            fighters_data.append(fighter)\n",
    "        except Exception as e:\n",
    "            print(f\"Couldn’t get data from {link}: {e}\")\n",
    "            errors.append((link, str(e)))\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    df = pd.DataFrame(fighters_data)\n",
    "    df.to_csv(\"ufc_fighters_dataset.csv\", index=False)\n",
    "    print(\"Done! Saved everything to ufc_fighters_dataset.csv\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"Had trouble with {len(errors)} links. You might want to check the log.\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167d003-c39e-4836-95e7-68fd27881c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_ufc_event_links_wikipedia():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_UFC_events\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    links = []\n",
    "\n",
    "    tables = soup.find_all(\"table\", {\"class\": \"wikitable\"})\n",
    "    for table in tables:\n",
    "        for row in table.find_all(\"tr\")[1:]:  # skip header\n",
    "            cols = row.find_all(\"td\")\n",
    "            if cols and len(cols) >= 2:\n",
    "                link_tag = cols[1].find(\"a\")\n",
    "                if link_tag and 'href' in link_tag.attrs:\n",
    "                    event_link = \"https://en.wikipedia.org\" + link_tag['href']\n",
    "                    links.append(event_link)\n",
    "    print(f\" {len(links)} UFC event links found.\")\n",
    "    return links\n",
    "\n",
    "def main():\n",
    "    print(\" Scraping UFC event links from Wikipedia...\")\n",
    "    wiki_links = get_ufc_event_links_wikipedia()\n",
    "\n",
    "    df = pd.DataFrame({\"Wikipedia Event Links\": wiki_links})\n",
    "    df.to_csv(\"wikipedia_ufc_event_links.csv\", index=False)\n",
    "    print(\"\\n Wikipedia event links saved to wikipedia_ufc_event_links.csv.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9105f90-ef90-44a6-a3a5-2bc95745ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5044b8fa-9f42-4497-b08f-1dd01338d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(url):\n",
    "    if not url.startswith(\"http\"):\n",
    "        return \"https://en.wikipedia.org\" + url\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee32d8d-81cf-41ef-8734-6b2a6136bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fight_cards_v2pro(event_url, event_name):\n",
    "    response = requests.get(event_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Couldn’t load page: {event_url}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    fight_data = []\n",
    "\n",
    "    tables = soup.find_all(\"table\", class_=\"wikitable\")\n",
    "    table_number = 0\n",
    "\n",
    "    for table in tables:\n",
    "        headers = [th.text.strip().lower() for th in table.find_all(\"th\")]\n",
    "        if any('fighter' in h or 'method' in h or 'weight class' in h for h in headers):\n",
    "            table_number += 1\n",
    "            if table_number == 1:\n",
    "                card_type = \"Main Card\"\n",
    "            elif table_number == 2:\n",
    "                card_type = \"Prelims\"\n",
    "            elif table_number == 3:\n",
    "                card_type = \"Early Prelims\"\n",
    "            else:\n",
    "                card_type = \"Other\"\n",
    "\n",
    "            rows = table.find_all(\"tr\")[1:]\n",
    "            for row in rows:\n",
    "                cols = row.find_all([\"td\", \"th\"])\n",
    "                if len(cols) < 2:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    fighter1 = cols[0].text.strip()\n",
    "                    fighter2 = cols[1].text.strip()\n",
    "                    method = cols[2].text.strip() if len(cols) > 2 else \"\"\n",
    "                    round_ = cols[3].text.strip() if len(cols) > 3 else \"\"\n",
    "                    time_ = cols[4].text.strip() if len(cols) > 4 else \"\"\n",
    "                    notes = cols[5].text.strip() if len(cols) > 5 else \"\"\n",
    "\n",
    "                    fight_data.append({\n",
    "                        \"Event Name\": event_name,\n",
    "                        \"Event URL\": event_url,\n",
    "                        \"Card Type\": card_type,\n",
    "                        \"Fighter 1\": fighter1,\n",
    "                        \"Fighter 2\": fighter2,\n",
    "                        \"Method\": method,\n",
    "                        \"Round\": round_,\n",
    "                        \"Time\": time_,\n",
    "                        \"Notes\": notes\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    return fight_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54d076-214a-4de6-9b67-b97225c42187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Loading all Wikipedia UFC event links...\")\n",
    "    links_df = pd.read_csv(\"wikipedia_ufc_event_links.csv\")\n",
    "    event_links = links_df[\"Wikipedia Event Links\"].tolist()\n",
    "    event_links = [clean_url(url) for url in event_links]\n",
    "\n",
    "    all_fights = []\n",
    "    print(f\"Scraping fight card data from {len(event_links)} events...\")\n",
    "\n",
    "    for i, link in enumerate(event_links):\n",
    "        print(f\"[{i+1}/{len(event_links)}] Getting data from: {link}\")\n",
    "        event_name = link.split(\"/\")[-1].replace(\"_\", \" \")\n",
    "        fights = extract_fight_cards_v2pro(link, event_name)\n",
    "        all_fights.extend(fights)\n",
    "        time.sleep(1)\n",
    "\n",
    "    df = pd.DataFrame(all_fights)\n",
    "    df.to_csv(\"wikipedia_ufc_fight_card_dataset_v2pro.csv\", index=False)\n",
    "    print(\"Done. Everything saved to wikipedia_ufc_fight_card_dataset_v2pro.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f320f-f05d-4f8b-895a-42eb1b0898bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
